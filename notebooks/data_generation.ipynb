{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5aaf77",
   "metadata": {},
   "source": [
    "# Data Generation for \"Technical Report - Assessing a Formal Model of Reflective Equilibrium\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd4e3d-f6a2-44b5-822b-042911c440dc",
   "metadata": {},
   "source": [
    "This notebook can be used to generate data that is similar in all relevant aspect to the data used the technical report [\"Assessing a Formal Model of Reflective Equilibrium\"](https://re-models.github.io/re-technical-report/). (It will not reproduce the same data since the data is the result of a random process.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0fb31-ed21-49ec-9ad9-feee89b1e58d",
   "metadata": {},
   "source": [
    "## How to run this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6756dc9e-63ab-4ea4-9655-e11a2035847e",
   "metadata": {},
   "source": [
    "There are several possibilities to execute this notebook. You can, for instance,\n",
    "\n",
    "1. execute this notebook on Colab: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/re-models/re-technical-report/blob/main/notebooks/data_generation.ipynb), or\n",
    "2. execute this notebook locally in, for instance, [JupyterLab](https://jupyter.org/) by cloning the Github repository of the report (for details, see <https://github.com/re-models/re-technical-report>).\n",
    "\n",
    "Note, however, that Colab is not suited to generate a dataset as large as the one used in the report. The predefined values will generate a small dataset on Colab. In every other environment, the predefined values correspond to those used to generate the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7676aa-caaf-4d50-baf1-3f2743589fac",
   "metadata": {},
   "source": [
    "## Installing and importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab768e2d-d968-4070-91fe-ed370b7f62d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install re-technical-report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721fd3ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "from rethon import GlobalREEnsembleGenerator\n",
    "from rethon.util import standard_model_params_varied_alphas\n",
    "from theodias.util import create_random_argument_list, tau_dump,tau_load, random_positions, inferential_density\n",
    "\n",
    "from theodias import (\n",
    "    BDDDialecticalStructure\n",
    ")\n",
    "\n",
    "from os import getcwd, path\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a25ffd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative path to data directory\n",
    "data_dir = path.join(Path(getcwd()).parent.absolute(), \"data\")\n",
    "#output_directory = path.join(path.dirname(getcwd()), \"data\")\n",
    "# Are we on Colab?\n",
    "on_colab = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5197a4f-262f-4687-85ae-a7ff64748499",
   "metadata": {},
   "source": [
    "## Creating dialectical structures and initial commitments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "248350f6-f837-4358-a049-158effbb0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_data_set_name = \"tau_alpha\"\n",
    "\n",
    "if on_colab:\n",
    "    sentence_pool_sizes = [6]\n",
    "else:\n",
    "    sentence_pool_sizes = [6,7,8,9]\n",
    "\n",
    "weights_list = [[1,0], # mean n_premises = 1\n",
    "                 [3,1], # mean n_premises = 1.25\n",
    "                 [1,1], # mean n_premises = 1.5\n",
    "                 [1,3], # mean n_premises = 1.75\n",
    "                 [0,1] # mean n_premises = 2\n",
    "                ]\n",
    "                  \n",
    "if on_colab:\n",
    "    # for illustrating purposes we only generate one tau for each sentence pool and each weight combination  \n",
    "    n_tau_per_sentence_pool = 1 \n",
    "else:\n",
    "    # 10 taus for each sentence pool and each weight combination (i.e., 200 structures in sum)\n",
    "    n_tau_per_sentence_pool = 10\n",
    "    \n",
    "max_n_premises = 2 # 1-2 premises per argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a29b1d9-735b-46b1-8d0c-718ea82f005e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creation of random dialectical structures\n",
    "tau_dict = {}\n",
    "i = 1\n",
    "for n_sentences in sentence_pool_sizes:\n",
    "    for weights in weights_list:\n",
    "        # just for keeping track\n",
    "        args_list = []\n",
    "        while len(args_list) < n_tau_per_sentence_pool:\n",
    "\n",
    "            arguments = create_random_argument_list(n_arguments_min=n_sentences-2, \n",
    "                                                    n_arguments_max=n_sentences+1,\n",
    "                                                    n_sentences=n_sentences, \n",
    "                                                    n_premises_max=max_n_premises,\n",
    "                                                    n_premises_weights=weights)\n",
    "\n",
    "            tau = BDDDialecticalStructure(n_sentences, arguments)\n",
    "\n",
    "            # used sentences\n",
    "            used_sentences = set(abs(s) for arg in arguments for s in arg)\n",
    "            # check inferential density and usage of all sentences\n",
    "            if (0.15<=inferential_density(tau)<=0.5) and (len(used_sentences)==n_sentences):           \n",
    "                tau_name = f'{tau_data_set_name}_{i:03d}'\n",
    "\n",
    "                tau.set_name(tau_name)\n",
    "                tau_dict[tau_name]= tau\n",
    "                args_list.append(arguments)\n",
    "                i+=1\n",
    "\n",
    "#print(tau_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12dd7786-8ff7-440c-bff3-8fd4ecfe7410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data set tau_alpha-2.\n"
     ]
    }
   ],
   "source": [
    "# saving dialectical structure as json file\n",
    "overwrite = False\n",
    "output_file_path = path.join(data_dir, f'{tau_data_set_name}.json')\n",
    "\n",
    "if not on_colab:\n",
    "    if path.exists(output_file_path) and not overwrite:\n",
    "        raise RuntimeError(f'Datafile {output_file_path} already exists. Remove file or set `overwrite` to true.')\n",
    "    print(f'Saving data set {tau_data_set_name}.')\n",
    "    with open(file=output_file_path, mode='w') as output_file:\n",
    "        tau_dump(tau_dict, output_file, indent=4, serialize_implementation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db032400-bf2b-4e34-bbce-9b4e31dbcb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating random initials commitments\n",
    "# number of initial commitment (for each sentence pool)\n",
    "if on_colab:\n",
    "    n_init_coms = 1\n",
    "else:\n",
    "    n_init_coms = 20\n",
    "    \n",
    "# for each sentence pool we generate `n_init_coms` initial commitments\n",
    "init_coms_dict = {n_sentence_pool: \n",
    "                  random_positions(n_sentences=n_sentence_pool, k=n_init_coms) for \n",
    "                  n_sentence_pool in sentence_pool_sizes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "664a21ae-8805-4ee3-be5e-3ebf469d619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data set coms_alpha2.\n"
     ]
    }
   ],
   "source": [
    "coms_data_set_name = \"coms_alpha\"\n",
    "\n",
    "# serializing into a JSON file\n",
    "output_file_path = path.join(data_dir, f'{coms_data_set_name}.json')\n",
    "\n",
    "if not on_colab:\n",
    "    if path.exists(output_file_path) and not overwrite:\n",
    "        raise RuntimeError(f'Datafile {output_file_path} already exists. Remove file or set over_write to true.')\n",
    "    print(f'Saving data set {coms_data_set_name}.')\n",
    "\n",
    "    with open(file=output_file_path, mode='w') as output_file:\n",
    "        tau_dump(init_coms_dict, output_file, indent=4, serialize_implementation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8c1db2-3026-485d-ae3f-41c5dd9a418e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RE ensemble runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1063d397-9bf5-472c-b38c-cfc85c93fbe1",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8710cc3-0ee2-4d0b-8922-f6da70118bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of taus in file: 200\n"
     ]
    }
   ],
   "source": [
    "## load dialectical structures\n",
    "if not on_colab:\n",
    "    tau_data_set_name = \"tau_alpha\"\n",
    "    tau_file_path = path.join(data_dir, f'{tau_data_set_name}.json')\n",
    "    input_file_path = tau_file_path\n",
    "    with open(file=input_file_path, mode='r') as input_file:\n",
    "        tau_dict = tau_load(input_file, use_json_specified_type=True)\n",
    "    print(f'Number of taus in file: {len(tau_dict.values())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7999bf99-a0bc-4da6-86de-c74d8dcee35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coms_data_set_name = \"coms_alpha\"\n",
    "# loading initial commitments\n",
    "if not on_colab:\n",
    "    coms_file_path = path.join(data_dir, f'{coms_data_set_name}.json')\n",
    "    input_file_path = coms_file_path\n",
    "    with open(file=input_file_path, mode='r') as input_file:\n",
    "        init_coms_dict = tau_load(input_file)\n",
    "    # converting str-keys to ints\n",
    "    init_coms_dict = {int(key):value for key, value in init_coms_dict.items()}\n",
    "#print(init_coms_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11356c37-ad53-4c3d-b189-e124dbb792a8",
   "metadata": {},
   "source": [
    "### Process parameters and used models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d68d0677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "# RE weights\n",
    "model_parameters_list = []\n",
    "\n",
    "if on_colab:\n",
    "    # corresponds to weights [ 0.25, 0.5, 0.75]\n",
    "    alpha_resolution = 3 \n",
    "else:\n",
    "    # corresponds to weights [ 0.1, 0.2, ..., 0.9]\n",
    "    alpha_resolution = 9\n",
    "\n",
    "for model_parameters in standard_model_params_varied_alphas(alpha_resolution):\n",
    "    for weight_name in model_parameters[\"weights\"].keys():\n",
    "        model_parameters[\"weights\"][weight_name] = round(model_parameters[\"weights\"][weight_name],2)\n",
    "    model_parameters_list.append(model_parameters)\n",
    "\n",
    "print(len(model_parameters_list))   \n",
    "#print(model_parameters_list)\n",
    "\n",
    "# model variants\n",
    "implementations = [# globally searching algorithm with quadratic G-function \n",
    "                   {'tau_module_name': 'theodias',\n",
    "                    'position_class_name':'StandardPosition',\n",
    "                    'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                    'reflective_equilibrium_module_name': 'rethon',\n",
    "                    'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibrium'},\n",
    "                   # globally searching algorithm with linear G-function\n",
    "                   {'tau_module_name': 'theodias',\n",
    "                    'position_class_name':'StandardPosition',\n",
    "                    'dialectical_structure_class_name': 'DAGDialecticalStructure',\n",
    "                    'reflective_equilibrium_module_name': 're_technical_report',\n",
    "                    'reflective_equilibrium_class_name': 'StandardGlobalReflectiveEquilibriumLinearG'},\n",
    "                   # locally searching algorithm with quadratic G-function \n",
    "                   {'tau_module_name': 'theodias',\n",
    "                    'position_class_name':'StandardPosition',\n",
    "                    'dialectical_structure_class_name': 'BDDDialecticalStructure',\n",
    "                    'reflective_equilibrium_module_name': 're_technical_report',\n",
    "                    'reflective_equilibrium_class_name': 'StandardLocalReflectiveEquilibriumWithGO'},\n",
    "                   # locally searching algorithm with linear G-function \n",
    "                   {'tau_module_name': 'theodias',\n",
    "                    'position_class_name':'StandardPosition',\n",
    "                    'dialectical_structure_class_name': 'BDDDialecticalStructure',\n",
    "                    'reflective_equilibrium_module_name': 're_technical_report',\n",
    "                    'reflective_equilibrium_class_name': 'StandardLocalReflectiveEquilibriumLinearGWithGO'},\n",
    "                    ]\n",
    "#list(implementations.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4a749e-725e-4106-a18f-0ead5e0de0b2",
   "metadata": {},
   "source": [
    "### Running ensembles and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b051f09-9495-488f-a838-8f72a463d03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-23 11:42:53,798 [INFO] rethon: Starting ensemble generation with 12 models runs (not counting branches)\n",
      "2024-02-23 11:42:57,213 [INFO] rethon: Starting ensemble generation with 12 models runs (not counting branches)\n",
      "2024-02-23 11:43:03,614 [INFO] rethon: Starting ensemble generation with 12 models runs (not counting branches)\n",
      "2024-02-23 11:43:08,307 [INFO] rethon: Starting ensemble generation with 12 models runs (not counting branches)\n",
      "2024-02-23 11:43:21,774 [INFO] rethon: Starting ensemble generation with 12 models runs (not counting branches)\n"
     ]
    }
   ],
   "source": [
    "output_file_name = 're_data_tau.csv'\n",
    "\n",
    "for tau in tau_dict.values():\n",
    "    ensemble_gen = GlobalREEnsembleGenerator(arguments_list = [tau.get_arguments()], \n",
    "                                            n_sentence_pool = tau.sentence_pool().size(),\n",
    "                                            initial_commitments_list = init_coms_dict[tau.sentence_pool().size()],\n",
    "                                            model_parameters_list = model_parameters_list,\n",
    "                                            implementations = implementations,\n",
    "                                            max_re_length = 100,\n",
    "                                            create_branches = True,\n",
    "                                            max_branches = 500)\n",
    "\n",
    "    if not on_colab:\n",
    "        ensemble_gen.ensemble_items_to_csv(\n",
    "                                        output_file_name=output_file_name,\n",
    "                                        output_dir_name = data_dir,\n",
    "                                        archive = False, # save the csv as archived tar.gz\n",
    "                                        save_preliminary_results = False,  \n",
    "                                        append=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
