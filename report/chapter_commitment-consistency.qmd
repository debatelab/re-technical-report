# Consistency {#sec-commitment-consistency}

## Background

Consistency is commonly seen as a necessary condition of coherence. Achieving consistency in RE is, therefore, of utmost importance. In contrast to the desiderata of faithfulness, systematicity and account (see @sec-mod), the desideratum of consistency is not hard-wired into the model. Although the agent is not allowed to choose commitments with flat contradictions (i.e., commitment sets of the form $\{s_i,\dots, \neg s_i\}$), they can choose dialectically inconsistent commitments (i.e., commitments that are inconsistent with respect to the inferential relationships encoded in the dialectical structure $\tau$). Or, more formally, a dialectically inconsistent set of commitments may maximize the achievement during the step of adjusting commitments. Accordingly, the process might end at a fixed point with dialectically inconsistent commitments. The question is, therefore, whether the explicitly modelled desiderata and the specification of the process are sufficiently conducive towards dialectical consistency.^[The main driving force for dialectical consistency is the desideratum of account. Since the choice of new theories is confined to dialectically consistent theories, account will favour commitments that are dialectically consistent.]  

In this chapter, we analyze the *dialectical consistency* of inputs and outputs (fixed points and global optima) of RE simulations, which can be examined from three different perspectives:

1. the consistency of output commitments
2. the "consistency case" that arises from combining the consistency status of initial and output commitments
3. the consistency of the union of output commitments and theory

Concerning 2., the juxtaposition of initial and output commitments allows for four cases, which are labelled as follows:

|                                   | endpoint commitments consistent   | endpoint commitment inconsistent  |
| ------                            | ------                            | ----                              |
| **initial commitments consistent**    | consistency preserving (CP)       | consistency eliminating (CE)      |   
| **initial commitments inconsistent**  | inconistency eliminating (IE)     | inconsistency preserving (IP)     |

CP Cases preserve or "transfer" consistency between initial and endpoint commitments. In IE cases, inconsistent initial commitments are revised for consistent endpoint commitments. IP cases fail to eradicate initial inconsistencies, and finally, there may be CE cases if inconsistencies are introduced to initially consistent commitments. 

From the viewpoint of model consolidation, the cases are interesting and relevant in various respects. High shares of IE cases would speak in favour of the model's revisionary power and signify progress towards establishing coherence by RE. Frequent IP cases, in turn, would speak against the model's revisionary power with respect to inconsistent initial commitments. Moreover, this could fuel the objection that RE (or the present model thereof) is overly conservative, such that "garbage in" (inconsistent initial commitments) leads to "garbage out" (inconsistent fixed point/global optimum commitments). High relative shares of CP cases are a desirable feature. Finally, frequent CE cases would be a truly worrisome result, as they would indicate that the model leads to a worsening in terms of consistency.

<!--
## Method

During the generation of an ensemble, we store the consistency status of intial commitments as well as the status for the commitments of every global optima or fixed points for every simulation setup. Furthermore, the consistency of the union of commitments and theory of a global optimum or a fixed point is determined as well. This allows to determine the relative shares of consistent outputs, consistency cases, and consistent unions among all outputs. These relatives shares are this study's main endpoints.

Note that fixed points can be counted in different ways. Taking a result-oriented perspective, we can consider unique fixed points per simulation setup, irrespective of whether they can be reached multiple times through different RE processes from a specific simulation setup. In contrast, we can also take a process-oriented perspective and count every "branch" of an RE process, Hence we might count one fixed point multiple times if it is the enpoint of different branches. In what follows, these  perspectives are reported separately, indicated by "(unique)" or "(all branches)".
-->

## Results

::: {.callout-note}
The results of this chapter can be reproduced with the Jupyter notebook located [here](https://github.com/re-models/re-technical-report/blob/main/notebooks/data_analysis_chapter_commitment-consistency.ipynb).
:::

### Consistent Outputs
#### Overall Results

```{python}
#| echo: false
#| label: tbl-consistency-outputs-go
#| tbl-cap: 'Relative share of consistent commitments among global optima'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistent_go_rp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]

display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```

```{python}
#| echo: false
#| label: tbl-consistency-outputs-fp-setups
#| tbl-cap: 'Relative share of consistent commitments among fixed points (result perspective)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistent_fp_rp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))

df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]


display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```

```{python}
#| echo: false
#| label: tbl-consistency-outputs-fp-branches
#| tbl-cap: 'Relative share of consistent commitments among fixed points (process perspective)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistent_fp_pp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]

display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```

**Observations: Consistent Outputs**

- Overall, the relative share of consistent output commitments is high for all model variants and output types, roughly ranging from 0.69 to 0.95
<!--
New: excluding erroneous simulation runs from the ensemble introduces small differences between global optima of local and global model variants
Old:
- The relative share of global optima with consistent outputs is identical for `QuadraticGlobalRE` and `QuadraticLocalRE`, as well as for `LinearGlobalRE` and `LinearLocalRE` in @tbl-consistency-outputs-go. (Explanation: The local model variants rely on their global counterparts to determine global optima. Hence, these results are not interesting for the present study, but included for the sake of completeness.)
--> 
- The overall relative share of consistent global optima commitments is slightly boosted for linear model variants compared to their quadratic counterparts in @tbl-consistency-outputs-go.
- The relative shares of consistent commitments among fixed points (result perspective: @tbl-consistency-outputs-fp-setups, and process perspective: @tbl-consistency-outputs-fp-branches) is slightly lower than the corresponding results for global optima in @tbl-consistency-outputs-go for `QuadraticGlobalRE`, `QuadraticLocalRE`, and `LinearGlobalRE`
- `LinearLocalRE` exhibits substantially higher relative shares of consistent commitments among fixed points (result and process perspective) 
- The number of fixed points reached through different branches (process perspective) in local model variants is substantially higher than for global model variants (@tbl-consistency-outputs-fp-branches)

#### Results Grouped by Sentence Pool Size

![Relative share of global optima with consistent commitments grouped by model variant and sentence pool size](figures/rel_consistent_go_by_sp_rp){#fig-cons-go-sp-rp}

![Relative share of fixed points (result perspective) with consistent commitments grouped by model variant and sentence pool size](figures/rel_consistent_fp_by_sp_rp){#fig-cons-fp-sp-rp}

![Relative share of fixed points (process perspective) with consistent commitments grouped by model variant and sentence pool size](figures/rel_consistent_fp_by_sp_pp){#fig-cons-fp-sp-pp}

**Observations**

- The relative share of global optima with consistent commitments slighty decrease for larger sentence pool sizes (@fig-cons-go-hm-rp).
- The closeness of results of `QuadraticGlobalRE` and `QuadraticLocalRE`, as well as `LinearGlobalRE` and `LinearLocalRE` in @fig-cons-go-hm-rp is due to the fact, that local variants rely on their global counterparts to determine global optima. Differences arise due to the exclusion of different erroneous runs.
- The relative share of fixed points with consistent commitments slightly decreases for larger sentence pool sizes (both perspectives in @fig-cons-fp-hm-rp and @fig-cons-fp-hm-pp) for `QuadraticGlobalRE`, `QuadraticLocalRE`, and `LinearGlobalRE`.
- In contrast, for `LinearLocalRE`, the relative share of fixed points with consistent commitments  remains roughly constant (result perspective in @fig-cons-fp-hm-rp) or sligtly increases (process perspective in @fig-cons-fp-hm-pp)

#### Results Grouped by Configuration of Weights

![Relative share of global optima with consistent commitments grouped by model variant and configuration of weights. Note that local variants are omitted due to almost analogous results.](figures/hm_consistent_coms_go_rp){#fig-cons-go-hm-rp}

![Relative share of fixed points (result perspective) with consistent commitments grouped by model variant and configuration of weights](figures/hm_consistent_coms_fp_rp){#fig-cons-fp-hm-rp}

![Relative share of fixed points (process perspective) with consistent commitments grouped by model variant and configuration of weights](figures/hm_consistent_coms_fp_pp){#fig-cons-fp-hm-pp}

**Observations**

- Linear models exhibit a "tipping line" for the relative share of global optima and fixed points with consistent commitments. For $\alpha_{A} > \alpha_{F}$, the relative share is consistently 1.0. See @sec-appendix-tipping for an explanation.
- In contrast, quadratic models show a gradient of smoother transitions between relative shares, increasing with higher weights for $\alpha_{A}$, and also to some extent with higher weights for $\alpha_{A}$.

### Consistency Cases

The results of this section are based on a more fine-grained distinction of cases that depend on the consistency status of initial and output commitments.

Note that the relative shares of cases have been calculated for consistent and inconsistent initial commitments separately. For example, the relative share of inconsistency eliminating cases (inconsistent input, consistent output) among global optima has been calculated with respect to all global optima that result from inconsistent inital commitments. 

Consequently, the relative share of inconsistency eleminating and inconsistency preserving cases add up to 1.0, and so do the relative shares of consistency preserving and consistency eliminating cases.

#### Overall Results

```{python}
#| echo: false
#| label: tbl-consistency-cases-go
#| tbl-cap: 'Relative share of consistency cases among global optima'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_cases_go_rp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]

display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```

![Relative share of consistency cases among global optima resulting from consistent initial commitments](figures/consistency_cases_go_ic_cons_rp){#fig-overall-go-ic-cons-rp width=70%}

![Relative share of consistency cases among global optima resulting from inconsistent initial commitments](figures/consistency_cases_go_ic_incons_rp){#fig-overall-go-ic-incons-rp width=70%}

```{python}
#| echo: false
#| label: tbl-consistency-cases-fp-setups
#| tbl-cap: 'Relative share of consistency cases among fixed points (result perspective)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_cases_fp_rp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))

df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]


display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```

![Relative share of consistency cases among fixed points (result perspective) from consistent initial commitments](figures/consistency_cases_fp_ic_cons_rp){#fig-overall-fp-ic-cons-rp}

![Relative share of consistency cases among fixed points (result perspective) from inconsistent initial commitments](figures/consistency_cases_fp_ic_incons_rp){#fig-overall-fp-ic-incons-rp}

```{python}
#| echo: false
#| label: tbl-consistency-cases-fp-branches
#| tbl-cap: 'Relative share of consistency cases among fixed points (process perspective)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_cases_fp_pp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]

display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```

![Relative share of consistency cases among fixed points (process perspective) from consistent initial commitments](figures/consistency_cases_fp_ic_cons_pp){#fig-overall-fp-ic-cons-pp}

![Relative share of consistency cases among fixed points (process perspective) from inconsistent initial commitments](figures/consistency_cases_fp_ic_incons_pp){#fig-overall-fp-ic-incons-pp}

**Observations: Consistency Cases**

<!--- As it is to be expected, there are no differences in relative shares for global optima for `QuadraticGlobalRE` and `QuadraticLocalRE`, as well as for `LinearGlobalRE` and `LinearLocalRE`.-->
- The relative share of consistency-preserving cases is high for all model variants and output types (@fig-overall-go-ic-cons-rp,@fig-overall-fp-ic-cons-rp, and @fig-overall-fp-ic-cons-pp). Consistency-eliminating cases occur very rarely.
- The relative share of inconsistency preserving cases slightly exceed the inconsistency eliminating cases for global optima and fixed points of `QuadraticGlobalRE`, `QuadraticLocalRE`, as well as `LinearGlobalRE` (@fig-overall-go-ic-incons-rp, @fig-overall-fp-ic-incons-rp, and @fig-overall-fp-ic-incons-pp).
- The result perspective makes clear that the linear local model variant reaches inconsistent output commitments from both consistent and inconsistent initial commitments (@fig-overall-fp-ic-cons-rp and @fig-overall-fp-ic-incons-rp), but the process perspective reveals that only very few branches result in these inconsistent output commitments (@fig-overall-fp-ic-cons-pp and @fig-overall-fp-ic-incons-pp).

#### Results Grouped by Sentence Pool Size

**Inconsistency Eliminating Cases**
![Relative share of inconsistency eliminating cases among global optima grouped by model variant and sentence pool size](figures/rel_inconsistency_eliminating_case_go_by_sp_rp){#fig-IE-go-sp}

![Relative share of inconsistency eliminating cases among fixed points (result perspective) grouped by model variant and sentence pool size](figures/rel_inconsistency_eliminating_case_fp_by_sp_rp){#fig-IE-fp-sp-rp}

![Relative share of inconsistency eliminating cases among fixed points (process perspective) grouped by model variant and sentence pool size](figures/rel_inconsistency_eliminating_case_fp_by_sp_pp){#fig-IE-fp-sp-pp}


**Consistency Preserving Cases**
![Relative share of consistency preserving cases among global optima grouped by model variant and sentence pool size](figures/rel_consistency_preserving_case_go_by_sp_rp){#fig-CP-go-sp}

![Relative share of consistency preserving cases among fixed points (result perspective) grouped by model variant and sentence pool size](figures/rel_consistency_preserving_case_fp_by_sp_rp){#fig-CP-fp-sp-rp}

![Relative share of consistency preserving cases among fixed points (process perspective) grouped by model variant and sentence pool size](figures/rel_consistency_preserving_case_fp_by_sp_pp){#fig-CP-fp-sp-pp}

<!--
**Inconsistency Preserving Cases**
![Relative share of inconsistency preserving cases among global optima grouped by model variant and sentence pool size](figures/rel_inconsistency_preserving_case_go_by_sp_rp){#fig-IP-go-sp}

![Relative share of inconsistency preserving cases among fixed points (result perspective) grouped by model variant and sentence pool size](figures/rel_inconsistency_preserving_case_fp_by_sp_rp){#fig-IP-fp-sp-rp}

![Relative share of inconsistency preserving cases among fixed points (process perspective) grouped by model variant and sentence pool size](figures/rel_inconsistency_preserving_case_fp_by_sp_pp){#fig-CP-fp-sp-pp}


**Consistency Eliminating Cases**
![Relative share of consistency eliminating cases among global optima grouped by model variant and sentence pool size](figures/rel_consistency_eliminating_case_go_by_sp_rp){#fig-CE-go-sp}

![Relative share of consistency eliminating cases among fixed points (result perspective) grouped by model variant and sentence pool size](figures/rel_consistency_eliminating_case_fp_by_sp_rp){#fig-CE-fp-sp-rp}

![Relative share of consistency eliminating cases among fixed points (process perspective) grouped by model variant and sentence pool size](figures/rel_consistency_eliminating_case_fp_by_sp_pp){#fig-CE-fp-sp-pp}
-->

**Observations**

- `LinearLocalRE` is the only model that tends to perform better with increasing sentence pool sizes with respect to all output types and conistency cases.

#### Results Grouped by Configuration of Weights

Due to the fact, that inconsistency eliminating and inconsistency preserving cases, as well as consistency eliminating and consistency preserving cases are complementary, we confine the presentation of results to two cases.

**Inconsistency Eliminating Cases**

![Relative share of inconsistency eliminating cases among global optima grouped by model variant and configuration of weights.](figures/hm_go_inconsistency_eliminating_cases_rp){#fig-IE-go}

![Relative share of inconsistency eliminating cases among fixed points (result perspective) grouped by model variant and configuration of weights.](figures/hm_fp_inconsistency_eliminating_cases_rp){#fig-IE-fp-rp}

![Relative share of inconsistency eliminating cases among fixed points (process perspective) grouped by model variant and configuration of weights.](figures/hm_fp_inconsistency_eliminating_cases_pp){#fig-IE-fp-pp}

**Observations: Inconsistency eliminating cases (IE)**

- Linear models exhibit a "tipping line" for IE cases among both global optima and fixed points. There are no IE cases where $\alpha_{A} < \alpha_{F}$, i.e. initial inconsistencies are never removed. In turn, the relative share of IE cases for $\alpha_{A} > \alpha_{F}$ is 1.0, i.e. initial inconsistencies are always removed. See @sec-appendix-tipping for an explanation.
- The case with non extreme values in linear models occur where $\alpha_{A} = \alpha_{F}$.
- In contrast, quadratic models have smooth transitions. High weights for account and systematicity, resulting in low weights for faithfulness, benefit the relative share of IE cases among global optima and fixed points.
<!--
- The relative shares of IE cases among global optima do not exceed their counterpart for fixed points.
-->
<!--
- The relative shares of IE cases among global optima are identical for `LinearGlobalRE` and `LinearLocalRE` in @fig-IE-go (as expected).
-->
- The relative shares of IE cases among fixed points (process perspective) in local model variants (@fig-IE-fp-pp) are slightly boosted in comparison to the consideration of unique fixed points (result perspectve) (@fig-IE-fp-rp).


**Consistency Preserving Case (CP)**

![Relative share of consistency preserving cases among global optima grouped by model variant and configuration of weights.](figures/hm_go_consistency_preserving_cases_rp){#fig-CP-go}

![Relative share of consistency preserving cases among fixed points (result perspective) grouped by model variant and configuration of weights.](figures/hm_fp_consistency_preserving_cases_rp){#fig-CP-fp-rp}

![Relative share of consistency preserving cases among fixed points (process perspective) grouped by model variant and configuration of weights.](figures/hm_fp_consistency_preserving_cases_pp){#fig-CP-fp-pp}


**Observations: Consistency Preserving Cases (CP)** 

- Overall, CP cases occur very frequently for all model variants and output types. In turn, the relative shares of CE cases ($1.0-CP$) are very low.
- Linear models exhibit a "tipping line" for CP cases among both global optima and fixed points. For $\alpha_{A} > \alpha_{F}$, consitency is always preserved. In turn, CE cases occur only for $\alpha_{A} \leq \alpha_{F}$.
- The influence of weight configurations is moderately at best.

<!--
**Inconsistency Preserving Cases (IP)**

![Relative share of inconsistency preserving cases among global optima grouped by model variant and configuration of weights.](figures/hm_go_inconsistency_preserving_cases_rp){#fig-IP-go}

![Relative share of inconsistency preserving cases among fixed points (result perspective) grouped by model variant and configuration of weights.](figures/hm_fp_inconsistency_preserving_cases_rp){#fig-IP-fp-rp}

![Relative share of inconsistency preserving cases among fixed points (process perspective) grouped by model variant and configuration of weights.](figures/hm_fp_inconsistency_preserving_cases_pp){#fig-IP-fp-pp}

**Observations: Inconsistency Preserving Cases (IP)**

- Linear models exhibit a "tipping line" for IP cases among both global optima and fixed points. There are no IP cases where $\alpha_{A} > \alpha_{F}$, i.e. initial inconsistencies are always removed. In turn, the relative share of IP cases for $\alpha_{A} < \alpha_{F}$ is 1.0, i.e. initial inconsistencies are never removed. See @sec-appendix-tipping for an explanation.
- The case with non extreme values in linear models occur where $\alpha_{A} = \alpha_{F}$.
- In contrast, quadratic models have smooth transitions. High weights for faithfulness boost the relative shares of IP cases among global optima and fixed points.



**Consistency Eliminating Cases (CE)**

![Relative share of consistency eliminating cases among global optima grouped by model variant and configuration of weights.](figures/hm_go_consistency_eliminating_cases_rp){#fig-CE-go}

![Relative share of consistency eliminating cases among fixed points (result perspective) grouped by model variant and configuration of weights.](figures/hm_fp_consistency_eliminating_cases_rp){#fig-CE-fp-rp}

![Relative share of consistency eliminating cases among fixed points (process perspective) grouped by model variant and configuration of weights.](figures/hm_fp_consistency_eliminating_cases_pp){#fig-CE-fp-pp}

**Observations: Consistency Eliminating Cases (CE)**

- Generally, the relative shares of CE cases are very low.
- Linear models exhibit a "tipping line" for CE cases among both global optima and fixed points. There are no CE cases where $\alpha_{A} > \alpha_{F}$. CE cases occur only for $\alpha_{A} \leq \alpha_{F}$.
- In contrast, quadratic models have smoother transitions. High weights for faithfulness boost the relative shares of CE cases among global optima and fixed points.

-->

### Consistent Unions

In this section, we will analyze the dialectical consistency of whole epistemic states---that is, the union of an epistemic state's commitments and theory. Since we already analyzed the consistency of fixed point commitments and global optima commitments in isolation, we will count only those inconsistencies that arise by combining commitments and theories. In other words, we will not consider inconsistencies that result from inconsistencies in the commitments.

#### Overall Results

```{python}
#| echo: false
#| label: tbl-consistency-union-go
#| tbl-cap: 'Relative share of global optima with a consistent union of commitments and theory'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_union_go_rp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]

display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```


```{python}
#| echo: false
#| label: tbl-consistency-union-fp-setups
#| tbl-cap: 'Relative share of fixed points (result perspective) with a consistent union of commitments and theory'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_union_fp_rp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))

df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]

display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```



```{python}
#| echo: false
#| label: tbl-consistency-union-fp-branches
#| tbl-cap: 'Relative share of fixed points (process perspective) with a consistent union of commitments and theory'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_union_fp_pp.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

keep_columns = [col for col in df.columns if "Standard deviation" not in col]

display(Markdown(df[keep_columns].to_markdown(index = False)))


#df.style.hide(axis="index")  
```

**Observations**

- The relative shares of consistent unions of commitments and theory among outputs with consistent commitments is very high for all model variants and output types.

#### Results Grouped by Sentence Pool Size

![Relative share of global optima with a consistent union of commitments and theory grouped by model variant and sentence pool size](figures/rel_consistent_union_go_by_sp_rp){#fig-cons-union-go-sp}

![Relative share of fixed points (result perspective) with a consistent union of commitments and theory grouped by model variant and sentence pool size](figures/rel_consistent_union_fp_by_sp_rp){#fig-cons-union-fp-sp-rp}

![Relative share of fixed points (process perspective) with a consistent union of commitments and theory grouped by model variant and sentence pool size](figures/rel_consistent_union_fp_by_sp_pp){#fig-cons-union-fp-sp-pp}

#### Results Grouped by Configuration of Weights

![Relative share of global optima with a consistent union of commitments and theory grouped by model variant and configuration of weights](figures/hm_consistent_union_go_rp){#fig-cons-union-go-hm}

![Relative share of fixed points (result perspective) with a consistent union of commitments and theory grouped by model variant and configuration of weights](figures/hm_consistent_union_fp_rp){#fig-cons-union-fp-hm-rp}

![Relative share of fixed points (process perspective) with a consistent union of commitments and theory grouped by model variant and configuration of weights](figures/hm_consistent_union_fp_pp){#fig-cons-union-fp-hm-pp}



## Conclusion

<!--
What do we want to add from <https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/ensemble-study-02-dataexploration-04.ipynb>?
-->

Overall, the present ensemble study concerning the three perspectives on the consistency of outputs of RE simulations provides positive results with respect to model variation. The overall relative shares of consistent outputs, inconsistency-eliminating and consistency-preserving cases, as well as consistent unions are satisfactorily high for all model variants.

According to analysing the results further with respect to the sentence pool size, `LinearLocalRE` seems to have the edge over the other model variants in view of increasing sentence pool sizes. Nonetheless, the severely restricted sample that forms the basis of this report would make an extrapolation to even larger sentence pool sizes a highly speculative matter. Further research in this direction is required.

In the more fine-grained analysis according to weigh configurations, we can observe regions of weight configurations that yield desirable behaviour. Moreover, these regions are robust across model variants. This provides at least some motivation to prefer some configurations over others. In particular, it is beneficial to consistency considerations if $\alpha_{A} > \alpha_{F}$.

There is a notable difference between quadratic and linear model variants (smooth transitions vs. tipping line), but on its own, this does not serve as a criterion to prefer some model variants over others. See the @sec-appendix-tipping for a presentation of analytical results that explain why linear model variants exhibit tipping lines.


 <!--A description how an RE process creates a very bad case can be found in [dataexploration-04](https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/ensemble-study-02-dataexploration-04.ipynb) of an earlier ensemble.-->

