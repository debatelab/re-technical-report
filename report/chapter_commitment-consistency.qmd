# Commitment consistency cases {#sec-commitment-consistency}

## Background

Consistency is commonly seen as a necessary condition of coherence, and thus achieveing consistency in RE is of utmost importance. This study considers the *dialectical consistency* of inputs and outputs (fixed points and global optima) of RE simulations. This allows to examine consistency from different perspectives:

1. the consistency of output commitments
2. the "consistency case" that arises from combining the consistency status of initial and output commitments
3. the consistency of the union of output commitments and theory.

Concerning 2., the juxtaposition of initial and output commitments allows for four cases, which are labelled as follows:

|                                   | endpoint commitments consistent   | endpoint commitment inconsistent  |
| ------                            | ------                            | ----                              |
| initial commitments consistent    | consistency preserving (CP)       | consistency eliminating (CE)      |   
| initial commitments inconsistent  | inconistency eliminating (IE)     | inconsistency preserving (IP)     |

Case (CP) preserves or "transfers" consistency between intial and enpoint commitments. In (IE) cases, inconsistent initial commitments are revised for consistent endpoint commitments. (IP) cases fail to eradicate initial inconsistencies, and finally there may be (CE) cases if inconsistencies are introduced to initially consistent commitments. 

From the viewpoint of model consolidation, the cases are interesting and relevant in various respects. High shares of 
(IE) cases would stand in support of the model's revisionary power and signify progress towards establishing coherence by RE. Frequent (IP) cases, in turn, would speak against the model's revisionary power with respect to inconsistent initial commitments. Moreover, this could fuel the objection that RE (or the present model thereof) is overly conservative, such that "garbage in" (inconsistent initial commitments) leads to "garbage out" (inconsistent fixed point/global optimum commitments). High relative shares of (CP) cases are a desireabe feature. Finally, frequent (CE) cases would be a truly worrysome result, as they would indicate that the model leads to a worsening in terms of consistency.

## Method

During the generation of an ensemble, we store the consistency status of intial commitments as well as the status for the commitments of every global optima or fixed points for every simulation setup. Furthermore, the consistency of the union of commitments and theory of a global optimum or a fixed point is determined as well. This allows to determine the relative shares of consistent outputs, consistency cases, and consistent unions among all outputs. These relatives shares are this study's main endpoints.

Note that fixed points can be counted in different ways. Taking a result-oriented perspective, we can consider unique fixed points per simulation setup, irrespective of whether they can be reached multiple times through different RE processes from a specific simulation setup. In contrast, we can also take a process-oriented perspective and count every "branch" of an RE process, Hence we might count one fixed point multiple times if it is the enpoint of different branches. In what follows, these  perspectives are reported separately, indicated by "(unique)" or "(all branches)".

## Results

### Overall Results
The following overall results come about by grouping the results only by model variant before calculating the relative shares.

#### Consistent Outputs

```{python}
#| echo: false
#| label: tbl-consistency_outputs_go
#| tbl-cap: 'Relative share of consistent commitments among global optima'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_outputs_go_setups.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```

```{python}
#| echo: false
#| label: tbl-consistency_outputs_fp_setups
#| tbl-cap: 'Relative share of consistent commitments among fixed points (unique)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_outputs_fp_setups.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))

df = df.round(3)


display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```

```{python}
#| echo: false
#| label: tbl-consistency_outputs_fp_branches
#| tbl-cap: 'Relative share of consistent commitments among fixed points (all branches)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_outputs_fp_branches.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```

**Observations: Consistent Outputs**

- Overall, the relative share of consistent output commitments are high for all model variants and output types, roughly ranging from 0.70 to 0.95
- The relative share of global optima with consistent outputs is identical for `QuadraticGlobalRE` and `QuadraticLocalRE`, as well as for `LinearGlobalRE` and `LinearLocalRE` in @tbl-consistency_outputs_go. (Explanation: The local model variants rely on their global counterparts to determine global optima. Hence, these results are not interesting for the present study, but included for the sake of completeness.)
- The overall relative share of consistent global optima commitments does not differ substantially between quadratic and linear model variants.
- The relative shares of consistent commitments among fixed points does not differ substantially from the results for global optima for `QuadraticGlobalRE`, `QuadraticLocalRE`, and `LinearGlobalRE`
- `LinearLocalRE` exhibits substantially higher relative shares of consistent commitments among fixed points (unique and all branches) 
- The number of fixed points reached through different branches in local model variants is substantially higher than for global model variants (@tbl-consistency_outputs_fp_branches)

#### Consistency Cases

The results of this section are based on a more fine-grained distinction of cases than before. 

```{python}
#| echo: false
#| label: tbl-consistency_cases_go
#| tbl-cap: 'Relative share of consistency cases among global optima'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_cases_go_setups.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```

![Relative share of consistency cases among global optima across all configuration of weights](figures/overall_consistency_cases_go_setups){#fig-overall-go}

```{python}
#| echo: false
#| label: tbl-consistency_cases_fp_setups
#| tbl-cap: 'Relative share of consistency cases among fixed points (unique)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_cases_fp_setups.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))

df = df.round(3)


display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```

![Relative share of consistency cases among fixed points (unique) across all configuration of weights](figures/overall_consistency_cases_fp_setups){#fig-overall-fp-setups}


```{python}
#| echo: false
#| label: tbl-consistency_cases_fp_branches
#| tbl-cap: 'Relative share of consistency cases among fixed points (all branches)'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_cases_fp_branches.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```

![Relative share of consistency cases among fixed points (all branches) across all configuration of weights](figures/overall_consistency_cases_fp_branches){#fig-overall-fp-branches}

**Observations: Consistency Cases**

- As it is to be expected, there are no differences in relative shares for global optima for `QuadraticGlobalRE` and `QuadraticLocalRE`, as well as for `LinearGlobalRE` and `LinearLocalRE`.
- The relative share of inconsistency eliminating and consistency preserving cases is high for all model variants and output types. Note that their sum corresponds to the relative share of consistent output commitments from above.
- In turn, the relative share of inconsistency preserving cases are small, and consistency eliminating cases occur very rarely.
- The linear local model variant reaches inconsistent outputs (@fig-overall-fp-setups), but only very few branches result in these commitments (@fig-overall-fp-setups).

#### Consistent Union

```{python}
#| echo: false
#| label: tbl-consistency_union_go
#| tbl-cap: 'Relative share of global optima with a consistent union of commitments and theory'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_union_go_setups.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```


```{python}
#| echo: false
#| label: tbl-consistency_union_fp_setups
#| tbl-cap: 'Relative share of fixed points (unique) with a consistent union of commitments and theory'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_union_fp_setups.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))

df = df.round(3)


display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```



```{python}
#| echo: false
#| label: tbl-consistency_union_fp_branches
#| tbl-cap: 'Relative share of fixed points (all branches) with a consistent union of commitments and theory'

import pandas as pd
from os import getcwd, path
from pathlib import Path
from IPython.display import Markdown, display


tables_output_dir = path.join(Path(getcwd()).parent.absolute(), "report", "tables")
file_name = 'table_consistency_union_fp_branches.csv'
df = pd.read_csv(path.join(tables_output_dir, file_name))
df = df.round(3)

display(Markdown(df.to_markdown(index = False)))


#df.style.hide(axis="index")  
```

**Observations: Consistent Union**

- The relative shares of consistent unions of commitments and theory among outputs with consistent commitments is very high for all model variants and output types.


### Results Grouped by Weight Configuration

#### Consistency Cases

**Inconsistency Eliminating Cases**

![Relative share of inconsistency eliminating cases among global optima grouped by model variant and configuration of weights.](figures/go_inconsistency_eliminating_cases_setups){#fig-IE-go}

![Relative share of inconsistency eliminating cases among fixed points (unique) grouped by model variant and configuration of weights.](figures/fp_inconsistency_eliminating_cases_setups){#fig-IE-fp-setups}

![Relative share of inconsistency eliminating cases among fixed points (all branches) grouped by model variant and configuration of weights.](figures/fp_inconsistency_eliminating_cases_branches){#fig-IE-fp-branches}

**Observations: Inconsistency eliminating cases (IE)**

- Linear models exhibit a "tipping line" for IE cases among both global optima and fixed points. There are no IE cases where $\alpha_{A} < \alpha_{F}$. IE cases occur only for $\alpha_{A} > \alpha_{F}$.
- In contrast, quadratic models have smooth transitions. High weights for account and systematicity, resulting in low weights for faithfulness, benefit the relative share of IE cases among global optima and fixed points.
- The relative shares of IE cases among global optima do not exceed their counterpart for fixed points
- The relative shares of IE cases among global optima are identical for `LinearGlobalRE` and `LinearLocalRE` in @fig-IE-go (as expected).
- The relative shares of IE cases among fixed points from all branches in local model variants (@fig-IE-fp-branches) are slightly boosted in comparison to the consideration of unique fixed points (@fig-IE-fp-setups).



**Consistency Preserving Case (CP)**

![Relative share of consistency preserving cases among global optima grouped by model variant and configuration of weights.](figures/go_consistency_preserving_cases_setups){#fig-CP-go}

![Relative share of consistency preserving cases among fixed points (unique) grouped by model variant and configuration of weights.](figures/fp_consistency_preserving_cases_setups){#fig-CP-fp-setups}

![Relative share of consistency preserving cases among fixed points (all branches) grouped by model variant and configuration of weights.](figures/fp_consistency_preserving_cases_branches){#fig-CP-fp-branches}

**Observations: Consistency Preserving Cases (CP)** 

- Overall, CP cases occur frequently (roughly between 0.40 and 0.60) for all model variants and output types
- The influence of weight configurations is moderately at best.
- The relative shares of CP cases among global optima are identical for `LinearGlobalRE` and `LinearLocalRE` in @fig-CP-go (as expected).


**Inconsistency Preserving Cases (IP)**

![Relative share of inconsistency preserving cases among global optima grouped by model variant and configuration of weights.](figures/go_inconsistency_preserving_cases_setups){#fig-IP-go}

![Relative share of inconsistency preserving cases among fixed points (unique) grouped by model variant and configuration of weights.](figures/fp_inconsistency_preserving_cases_setups){#fig-IP-fp-setups}

![Relative share of inconsistency preserving cases among fixed points (all branches) grouped by model variant and configuration of weights.](figures/fp_inconsistency_preserving_cases_branches){#fig-IP-fp-branches}

**Observations: Inconsistency Preserving Cases (IP)**

- Linear models exhibit a "tipping line" for IP cases among both global optima and fixed points. There are no IE cases where $\alpha_{A} > \alpha_{F}$. IP cases occur only for $\alpha_{A} < \alpha_{F}$.
- In contrast, quadratic models have smooth transitions. High weights for faithfulness boost the relative shares of IP cases among global optima and fixed points.

**Consistency Eliminating Cases (CE)**

![Relative share of consistency eliminating cases among global optima grouped by model variant and configuration of weights.](figures/go_consistency_eliminating_cases_setups){#fig-CE-go}

![Relative share of consistency eliminating cases among fixed points (unique) grouped by model variant and configuration of weights.](figures/fp_consistency_eliminating_cases_setups){#fig-CE-fp-setups}

![Relative share of consistency eliminating cases among fixed points (all branches) grouped by model variant and configuration of weights.](figures/fp_consistency_eliminating_cases_branches){#fig-CE-fp-branches}

**Observations: Consistency Eliminating Cases (CE)**

- Generally, the relative shares of CE cases are very low.
- Linear models exhibit a "tipping line" for CE cases among both global optima and fixed points. There are no CE cases where $\alpha_{A} > \alpha_{F}$. IP cases occur only for $\alpha_{A} < \alpha_{F}$.
- In contrast, quadratic models have smoother transitions. High weights for faithfulness boost the relative shares of CE cases among global optima and fixed points.


## Conclusion

<!--
What do we want to add from <https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/ensemble-study-02-dataexploration-04.ipynb>?
-->

Overall, the present ensemble study concerning the three perspectives on consistency of outputs of RE simulations provides positive results with respect to model variation. The overall relative shares of consitent outputs, inconsistency eliminating and consistency preserving cases, as well as consistent unions are satisfactorily high for all model variants.

In the more fine-grained analysis according to weigh configurations, we can observe regions of weight configurations that yield desirable behaviour. Moreover, these regions are robust across model variants. This provides at least some motivation to prefer some configurations over others. In particular it is benificial to consistency considerations if $\alpha_{A} > \alpha_{F}$.

There is a notable difference between quadratic and linear model variant (smooth transitions vs. tipping line), but this does not serve as a criterion to prefer some model variant over the others.

 <!--A description how an RE process creates a very bad case can be found in [dataexploration-04](https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/ensemble-study-02-dataexploration-04.ipynb) of an earlier ensemble.-->

## Appendix
<!-- Move to a dedicated chapter for appendices?-->

### The Tipping Line of Linear Model Variants

A *linear model variant*, is a model that differs from the model provided by @beisbart_making_2021 only in that the measures involve the linear function $G$ instead of the quadratic one. This variant exhibits a *tipping line* in ternary plots that marks off configurations of weights that lead to drastically different behaviour with respect to consistency considerations or the attainment of full RE states, for example. 

We can characterise the tipping line as an equation that relates $\alpha_{A}$ and $\alpha_{S}$:
$$
\begin{equation} \label{eq:lin}
  \alpha_{A} = \frac{1-\alpha_{S}}{2}  
\end{equation}
$${#eq-lin}
The boundary condition $\alpha_{A} + \alpha_{S} + \alpha_{F} = 1$ allows us to rewrite @eq-lin in an even simpler form:
$$
\alpha_{A} = \alpha_{F}
$$
Consequently, the tipping line splits the space of weight configuration in two regions $\alpha_{A} < \alpha_{F}$ and $\alpha_{A} > \alpha_{F}$. For the latter region, where account receives more weight than faithfulness, we have some interesting analytical results.

The following proposition and its corollaries help to explain the salient change in the behaviour of linear model variants when crossing the tipping line.

**Proposition**
Assume that a dialectical structure $\tau$ and some initial commitments $C_{0}$ are given. Moreover, assume $\alpha_{A} > \alpha_{F}$ for a configuration of weights $(\alpha_{A}, \alpha_{S}, \alpha_{F})$ in a linear model variant. Then all global optima (relative to $C_{0}$) according to the achievement function specified by the configuration of weights are full RE states.

**Corollaries**
The linear model variants exhibit the following behaviour for $\alpha_{A} > \alpha_{F}$:

- For global optima, there no inconsistency preserving cases
- Consistency eliminating cases do not occur for global optima

In contrast, for $\alpha_{A} < \alpha_{F}$ the following holds for the linear model variants:

- Inconsistency eliminating cases do not occur for global optima

**Open questions**

- Interestingly, the corollaries almost always hold for fixed points as well. However, an analoguous proposition for fixed points would require a different proof.


**Proof sketch**

Intuitively, $\alpha_{A} > \alpha_{F}$ means that account trumps faithfulness, which allows to select commitments ignoring faithfulness so that they are fully and exclusively accounted for by a theory.

Assume that an epistemic state $(C, T)$ is a global optimum according to the achievement function $Z$ given some initial commitments $C_{0}$ and a configuration of weights  $(\alpha_{A}, \alpha_{S}, \alpha_{F})$ such that $\alpha_{A} > \alpha_{F}$. We need to show that $(C, T)$ is a full RE state, i.e., that $T$ fully and exclusively accounts for $C$ (FEA), or equivalently, $A(C, T) = 1$.

For a proof by contradiction, assume that $$A(C, T)=G(\frac{D_{0,\,0.3,\,1,\,1}(C,\overline{T})}{n}) < 1,$$ which holds only if $D_{0,\,0.3,\,1,\,1}(C,\overline{T}) > 0$. In other words, there is at least one sentence $s$ (negated or unnegated) for which there is a positive contribution to the Hamming distance. In particular, we have the following cases:

i. $\overline{T}$ extends $C$ with respect to $s$: $+0.3$
ii. $\overline{T}$ contracts $C$ with respect to $s$: $+1$
iii. $\overline{T}$ and $C$ contradict each other with respect to $s$: $+1$

Each case of changing $C$ with respect to $s$, yielding new commitments $C'$, impacts the contributions to the Hamming distances for account and faithfulness. Note that systematicity is not affected by changing the commitments.

The complete linearity of the achievement function allows to distribute ("push in") the weights $\alpha_{A}$ and $\alpha_{F}$ over the individual contributions of the hamming distances.

Since the achievement function is optimised for minimal contributions and $\alpha_{A} > \alpha_{F}$, it is always more attractive to change the commitments to increase account rather than faithfully respecting the initial commitments. This argument can be repeated for every sentence for which $C$ and $\overline{T}$ differ.

In summary, if $(C, T)$ is a global optimum but $A(C, T) < 1$, then there is a position $(C', T)$ such that $A(C, T) < A(C', T)$ contradicting $(C, T)$ being a global optimum. Consequently, we must have $A(C, T) = 1$, i.e., $T$ accounts fully and exclusively for $S$ (FEA). This shows that $(C, T)$ is a full RE state.

*Remark*

Note that this argument does not work for quadratic model variants, and in particular, the default model of  @beisbart_making_2021. 
Remember that the Hamming distance $D$ is a summation of penalties. Consequently, squaring the hamming distance yields a polynomial expression where every contributing penalty "interferes" by multiplication with the others. This blocks the above strategy of comparing the contributions and distributing the weights $\alpha_{A}$ or $\alpha_{S}$ over these expressions. In the quadratic models of the above ensemble study, we can observe a gradual transition between configurations that yield global optima, which exhibit a specific behaviour, to configurations that almost certainly fail in this respect.