# Introduction

@beisbart_making_2021 introduced a formal model of reflective equilibrium based on the theory of dialectical structures [@betz_theorie_2010;@betz_debate_2013], which, according to them, can be used to better understand the method of reflective equilibrium and to assess its potential to yield better epistemic states. Their discussion of the model is mostly based on an illustrative example. An assesment of how the model behaves under a wider spectrum of circumstances went beyond the scope of their work.

This report summarizes findings of assessing the RE model more thouroughly by, first, running the model to determine fixed points of the RE process and calculating global optima under a wide range of configurations and, second, by tweaking the original model. The simulation outcomes of three model variants are compared to the ones of the original model.^[The results of @beisbart_making_2021 are based on a Mathematica implementation of the model (see [{{< var link.remoma >}}]({{< var link.remoma >}})). Here, we rely on a reimplementation in Python ([rethon]({{< var link.rethon >}})).]

<!--
+ ToDo: Here we should describe the metrics and criteria more thoroughly, based on:
+ [metrics](https://github.com/debatelab/re-studies/blob/master/documents/ideensammlung_ensemblestudien.md) 
+ and [consolidation criteria](https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/documents/model-validation.md)
-->

<!-- ToDo: Add links to other chapters -->

At the outset, there is a plethora of metrics that could be used to examine the performance of the formal model and variants thereof. Let us motivate a small selection of desiderata for model validation, which we are going to address in individual explorative studies later.

- @sec-go-and-fp: Are global optima reachable, i.e. are they fixed points of RE processes?

The formal model allows to distinguish clearly between the *static* aspect of *equilibrium states* and the *dynamic* aspect of *equilibration processes* in RE. This is implemented in the formal model by yielding two kinds of output epistemic states from given inputs: First, global optimization of the achievement function $Z$ results in *global optima*. Second, in a semi-globally optimizing process of alternating adjustments of commitments and theory leads to *fixed points*. Note that both global optima and fixed points may not be uniquely determined given an input. There may be multiple, equally well performing epistemic states according to the achievement function $Z$, or there may  be ties between candidates during equilibration, which leads to branching processes resulting in multiple fixe points.

The global optimization can be achieved by brute force and going through every combination of commitments and theory (worst case). In contrast, the semi-globally optimizing equilibration process of adjustments can already be understood as a heuristic to reach global optimal states, but proccesses can be caught up in local optima. This holds even more so for the local model variant described below.

Consequently, it is an interestng question for model validation whether fixed points are global optima. Conversely, we can also ask whether there are global optima that are not reachable by equilibration processess (given specific inputs).

@sec-full-re-states: Are global optima/fixed points full RE states?

Elaborate accounts of RE require that states of RE are optimal [REFERENCES]. Otherwise, there is room for improvement. Are global optima in the formal model RE states? @beisbart_making_2021 propose additional requirements for globally epistemic states to qualify as (full) RE states:

- (FEA) The theory should account fully and exclusively for 

It is important to note that being in a globally optimal state does not guarantee (CCT) or (FEA). Thus, it is an important task for model validation to check whether, or in which circumstances the formal model yields outputs that satisfy (CCT) or (FEA) in addition to global optimality.

- @sec-commitment-consistency: Are commitments from global optima and fixed points free of inconsistencies?

Consistency is commonly seen as a necessary condition of coherence, and thus achieveing consistency in RE, which is commonly understood to involve coherentist aspects of justification, is of utmost importance.
  
- @sec-extreme-values: Do global optima and fixed points have extreme values (maxima, minima) in their measures?

The achievement function $Z$ aggregates three measures, namely for the desiderata of account $A$, systematicity $S$, and faithfulness $F$. Moreover, the measures are weighted in $Z$ to model trade-offs between the desiderate (e.g. give up on faithfulness to increase account). As optimzize $Z$ it is interesting to study the trade-offs and whether or in which circumstances maximal or minimal values are taken by these measures.

<!-- Minimal models should answer the subquestions in the affirmative to a sufficient degree. However, undesirable behaviour of a model variant should be explainable in terms of additional input, apart from the model specification, which is required to run simulations.-->

Additionally, we address the following questions (@sec-general-props):

- Is the union of commitments and theory of a global optimum/fixed point consistent? - (CCT) The commitments and the theory should be consistent with each other
- How many steps does an RE process take?
- Does an RE promote principles in theories?
- Are the results from the published paper reproducible?

## Modelling reflective equilibration

<!--
+ Suggestion: A short general descripription of the RE-Model (with links to more elaborate descriptions).
-->

For the original and naturally most detailed presentation of the formal RE model, see @beisbart_making_2021. The present section is based on condensed material from @freivogel_converge_2023.



![Illustrative diagram of the formal model of RE provided by @beisbart_making_2021. The epistemic state, which consists of a set of commitments and a theory, is subject to operationalised desiderata for RE states (bold arrows). Rules for alternating adjustments of commitments and theory specify a process of equilibration that sets out from initial commitments.](figures/model_schematics.png){#fig-model-schematics}

The epistemic state $(C, T)$ of an agent consists of a set of commitments $C$ and a theory $T$. 
Both components are represented as *positions* in the framework of dialectical structures @betz_theorie_2010, @betz_debate_2013, but it suffices to think of positions as sets of accepted sentences. 
The sentences stem from a finite pool of sentences $\mathcal{S}$, which is closed under negation. $\mathcal{S}$ is part of a dialectical structure $\tau$, which also includes a set of deductively valid arguments $\mathcal{A}$. 
We can interpret the dialectical structure to form the background of an RE inquiry. 
The sentence pool delineates a subject matter, and the deductively valid arguments are assumed to ``comprise not just the valid arguments, but also the arguments that are valid *given the relevant background theories*'' [@beisbart_making_2021, p. 460].

A position is *minimally consistent* if and only if it does not contain flat contradictions (i.e., a sentence and its negation). 
On top of that, the arguments of the dialectical structure allow us to define a more demanding notion of consistency. 
A position is *dialectically* consistent if it is minimally consistent and satisfies all inferential relations that arise from the arguments of a dialectical structure. 
Sets of commitments are required to be minimally consistent, and theories must be dialectically consistent.

The bold arrows in Figure @fig-model-schematics stand for three epistemic desiderata that are included in elaborate accounts of RE. At the center, we have \emph{account}. The corresponding measure $A(C, T)$ operationalises how well the commitments $C$ fit to what is inferable from the theory $T$ given the dialectical structure $\tau$. For formal details of all measures, see [@beisbart_making_2021, pp. 464-466]. Being able to resolve conflicts in different ways indicates that an agent needs to balance multiple epistemic desiderata. Desiderata are directed at the components of an epistemic state, come in degrees, and can ``pull’’ in different directions.

On the right hand side of Figure @fig-model-schematics, there is the desideratum of *systematicity*. A theory should "do justice to epistemic goals" in order to systematise the commitments (e.g., \citealp[7928]{BB2020}). The operationalised measure $S(T)$ depends on the number of elements of a theory and the number of sentences that can be inferred from it.

Finally, there is the desideratum of *faithfulness* on the left hand side in Figure @fig-model-schematics. It can be motivated by the view that the current commitments should "respect" the initial commitments by not changing the topic, or that a "tie" to credible or tenable initial commitments contributes to the justification of the resulting state \citep[447]{BBB2021}. $F(C \,\vert\, C_{0})$ measures the closeness of current commitments $C$ and initial commitments $C_{0}$.

Trade-offs between desiderata are modelled in an achievement function that aggregates the weighted measures.
$$Z(C, T\,\vert\, C_{0}) = \alpha_{A}\cdot A(C, T) + \alpha_{S}\cdot S(T) + \alpha_{F}\cdot F(C\,\vert\, C_{0}),$$
where $\alpha_{A}$, $\alpha_{S}$ and $\alpha_{F}$ are real-valued numbers between $0$ and $1$ that sum up to $1$. 
The achievement function assigns to every epistemic state $(C, T)$ a value of "overall betterness" relative to what we can call an *epistemic situation* of an agent, i.e., a dialectical structure $\tau$, a set of initial commitments $C_{0}$, and a configuration of weights $(\alpha_{A}, \alpha_{S}, \alpha_{F}$).  
The epistemic situation captures the subject matter of inquiry, its background, and the means to handle trade-offs between epistemic desiderata.

A *global optimum* relative to an epistemic situation is a state $(C, T)$ such that there is no other epistemic state that performs strictly better according to $Z$ than $(C, T)$.
The formal model also gives explicit rules for a process of equilibration that sets out from the initial commitments $C_{0}$. 
In an alternating fashion, theory and commitments are adjusted to optimise the achievement function until a stopping condition is met (for details, see @beisbart_making_2021 [p. 449]). 
An epistemic state that results from the equilibration process is called a *fixed point*.


## Model variations

The ensemble studies include four variants of the formal RE model that result from a combination of two independent alterations in the formal model. The first alteration concerns the "shape" of the function that measures the desiderata. It is quadratic by default in @beisbart_making_2021, but can be contrasted with a linear model variant. Second, the (semi-)global optimization during equilibrations (default in @beisbart_making_2021) can be compared to a locally optimizing model variant. 


The combinations of them odel alterations are labelled as follows: `QuadraticGlobalRE` (in short, `QGRE`), `QuadraticLocalRE` (in short, `QLRE`), `LinearGlobalRE` (in short, `LGRE`) and `LinearLocalRE` (in short, `LLRE`),. Note that `QGRE` corresponds to the "default" model of the published paper by @beisbart_making_2021. The subsequent sections present the model alterations in more detail.

### Quadratic and Linear Measures

The *achievement function* plays an important role for both global optima and adjustment steps in RE processes. Global optima maximize the achievement function and candidate commitments or theories in adjustment steps are selected according to their score in the achievement function.

The  monotonically decreasing function $G$, which is part of the measures for desiderata in the achievement function $Z$ involves a quadratic term per default in the published paper of @beisbart_making_2021. In particular, we have $G(x)= 1-x^2$. However, the shape of $G$ is not explicitly motivated. It can be replaced by a "simpler", linear term to examine the repercussions of such a variation. The linear model variant relies on $G(x)= 1-x$.

<!--
+ ToDo: Description of locally searching model variants.
-->

### Semi-globally and locally optimizing equilibration processes 

The (semi-)global optimzation during equilibration according to the published model involves the consideration of *all* commitments candidates and *all* theory candidates at each respective adjustment step. This is computationally costly as the search space grows exponentially with the number of involved sentences. In conrast *locally* optimizing processes, that only allow for small changes in a neighborhood of the current position, escape this problem. Moreover, local RE processes may be considered to model "piecemeal" adjustments, which may be the only feasible approach for rationally bounded agents engaging with RE. 


The *local* model variant restricts available candidates during adjustment steps in RE processes to a neighborhood of the position that represents the current commitments or theory, respectively.

The depth of this neighborhood is defined in terms of the edit Hamming distance between positions. Let $\mathcal{P}$ denote the set of minimally consistent positions of a dialectical structure $\tau$.

$$
neighborhood(P, d) = \lbrace Q\in\mathcal{P}\vert D_{0, 1, 1, 1}(P, Q)\leq d\rbrace
$$

For a sentence pool size of $n$, the number of positions in the (inclusive) neighborhood of a position is $$\sum_{k=0}^{d} \binom{n}{k} \cdot 2^k,$$ where $d$ denotes the neighborhood depth. For $d = 1$ the number of positions in the neighbourhood grows linearly with respect to the number of sentences, in particular $2n + 1$.

For a neighborhood depth $d = 1$, i.e., a single adjustment of an element in a position per step, the resulting process can be seen to proceed in a ``piece-meal'' fashion. Formally, this can be implemented in the rules for adjustment steps from @beisbart_making_2021 [p. 466] by restricting the candidates in (Theory Adjustment) to $neighbourhood(T_{i}, d)$, and analogously to $neighbourhood(C_{i}, d)$ for (Commitment Adjustment). The handling of ties and the stopping rule remain unchanged.

To illustrate the difference between global, semi-global and local optimization, think of epistemic states $(C, T)$ as cells on a appropriately sized, possibly non-square, chess board.^[Note that the two-dimensional representation of the epistemic states in the subsequent figures is purely illustrative. There is no inherent linear order among positions, which can be understood as points in an $n$-dimensional discrete space.] The unbounded, globally optimising agent can overview the entire board at once (Figure @fig-grid-global), while a semi-globally optimizing agent can evaluate only a single row or column per adjustment step (Figure @fig-grid-semi-global). Finally, only candidates from a small neighborhood of the current position are available to the locally optimizing agent only during an adjustment step (Figure @fig-grid-local).

![Global optimization: All epistemic states are available.](figures/grid_global.png){width=66%  #fig-grid-global}

![Semi-global optimization: All sets of commitments and all theories are available in an alternating fashion while the other component is held fixed.](figures/grid_semi_global.png){width=66% #fig-grid-semi-global}

![Local optimization (alternating): Available commitments(row)/theories (column) are restricted to a neighborhood of the current state in an alternating fashion while the other component is held fixed.](figures/grid_local.png){width=66% #fig-grid-local}


<!--
+ Regarding the footnote: Should we include a discussion of other model variants. We also have a thourgough analysis of other systsematicity suggestions.
+ See: 
    + <https://github.com/debatelab/re-studies/blob/master/notebooks/remodel_revisions.ipynb>
    + <https://github.com/debatelab/re-studies/tree/master/projects/systematicity_study>
-->

<!--
ToDos:

+ Add perhaps one or some few examples as figures.
+ Do we have to reproduce the ensembles 1-4 with the current algorithm to generate maps?
-->

## Ensembles

Every simulation of an RE process and the calculation of global optima requires to specify inputs: i) the model variant, ii) the dialectical structure, iii) weighting of the measures, and iv) the initial commitments. Let us call a specification of inputs i)-iv), which allows to run simulation, a *configuration*. Every configuration yields a simulation of a possibly branching RE processess and a set of global optima (i.e. commitment-theory-pairs that maximize the achievement function). <!--The features of every configuration and its outcomes are stored in a row of a table (stored as comma-separated values (.csv), for a complete l). For a complete list of columns, see the [API documentation](http://argunet.philosophie.kit.edu/remodel-apidocs/api-docs/api-ensemble-generation.html)-->Generating an ensemble includes the following tasks and requires the specification of additional parameters.


*Size of sentence pool*

Due to the exponential growth of candidate commitments and theories, which all have to be considered for global optima and semi-global adjustment steps in RE processes, the ensembles include sentence pools with a small number of unnegated sentences (around 5 to 8 sentences). <!--The generation of ensembles is handled by a module ([ensemble_generation.py](https://git.scc.kit.edu/debatelab/re-python/-/blob/master/remodel/ensemble_generation.py)) that can be executed from a notebook ([ensemble-study-02-data-generation.ipynb](https://git.scc.kit.edu/debatelab/re-python/-/blob/master/projects/ensemble_study_02/ensemble-study-02-data-generation.ipynb)).--> 

*Automatically generated dialectical structures*

<!--The early ensembles (01-04) rely on a first version of creating random arguments for a dialectical structure. Inspite of initial measures to organize the arguments (e.g. preventing unnconnected clusters of arguments) the resulting dialectical structures still have a tendency to produce chaotic argument maps. In an attempt to generate more orderly structures, we refined the creation of random dialectical structures further. At this point, t-->The creation of random dialectical structures includes the following parameters: The number of unnegated sentences in the sentence pool, the number of arguments, the (maximal) number of premises per argument and whether there is variation, and the (minimal) number of principles. A sentence is called *principle* if and only if it occurs in at least one argument as premise and it or its negation does not occur as a conclusion in any argument. The random generation ensures that the dialectical structure contains the minimal number of principles, but there may be more sentences that satisfy the condition, too.

In addition, the creation of arguments ensures that all (unnegated) sentences are used in the arguments, and there is some preference for sentences that occur fewer times. Before a new candidate argument is added to the other arguments of the dialectical structure under construction, it has to pass a series of test conditions: The new argument 
- is not question-begging, i.e. the conclusion is not part of the premises
- is not attack-reflexive, i.e. the negation of the conclusion is not part of the premises
- has premises that are not a subset of premises of another argument
- is jointly satisfiable with the other arguments
- reduces the number of complete consistent postions, if it is added to the dialectical structure

<!--Visual comparison of argument maps ([create_random_arguments](https://git.scc.kit.edu/debatelab/re-python/-/tree/master/projects/ensemble_study_02/data/create_random_arguments) vs. [create_random_arguments2](https://git.scc.kit.edu/debatelab/re-python/-/tree/master/projects/ensemble_study_02/data/create_random_arguments2)), which can be created on demand or automatically during the generation of ensembles.-->

<!--
+ Do we discuss in this report findings of the Semmelweiss example? If not, the para is irrelevant here, right?
-->
Apart from generating ensembles with randomly generated dialectical structures, other ensembles are based on  handwritten examples (Semmelweiss example, variations of the standard example), that allow for a more intuitive interpretation of results.

The *inferential density* of a dialectical structure $\tau$, $D(\tau) = \frac{n-lg(\sigma)}{n}$, where $n$ is the number of unnegated sentences in the sentence pool and $\sigma$ is the number of complete and consistent extensions in $\tau$, was kept between $0.05$ and $0.5$.

*Random selection of initial commitments*

There are $3^{n}$ minimally consistent set of sentences that serve as initial commitments. To create intial commitments by chance, an integer between 1 and  $3^{n}$ is randomly chosen, converted to a ternary representation and initialized as a position in the Python implementation.


*Resolution of weights*

In order to explore different values for $\alpha_{A}$, $\alpha_{S}$ and $\alpha_{F}$ in the achievement function, a resolution (i.e. the separation of the unit intervall $[0, 1]$ into intervalls of equal length) of weights can be specified for an ensemble. In practice, every combination of $\alpha_{A}$ and $\alpha_{S}$ are , and $\alpha_{F}$ is set so that they satisfy the boundary condition $\alpha_{A} + \alpha_{S} + \alpha_{F} = 1$. 

<!-- 
+ ToDo: Then we should rely the analysis only on ensembles with $\alpha_{F} \neq 0$.
+ ToDo (?): Explain (more thouroughly or shortly) the findings of <https://github.com/debatelab/re-studies/blob/master/notebooks/Faithfulness_0_is_a_bad_idea.ipynb>.
-->
The extreme value of $\alpha_{F} = 0$ is excluded (!from the later ensembles!) since it produces all and only singleton theories (and their closure) to be global optima. 

<!--
+ ToDo: Revise this table.
    + Do we use every ensemble? 
    + Can we perhaps aggregate some ensembles into one?
+ For more details on the used ensembles, see <https://github.com/debatelab/re-studies/tree/master/projects/ensemble_study_02/data>
-->
*Overview of ensembles*

This study is based on different ensembles, which differ with respect to the following properties:

| ensemble | rows | dialectical structure generation |  dialectical structures | initial commitments | alpha resolution (count) | branching processes | principles |
| -- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 01 | 54000 | old random | 30 | 10 | steps: 0.1 steps (45) | no | no |
| 02 | 45000 (incomplete) | old random| 40 | 10 | steps: 0.1 (45) | no | no |
| 03 | 320 | standard variations | 8 | 10 | a: 0.35, s: 0.55, f: 0.1 (1) | no | no |
| 04 | 3200 (+ 320) | standard variations | 8 | 10 | steps: 0.2 (10) | no | no |
| 05 | 69000 | new random | 39 | 10 | steps: 0.1 (45) | no | no |
| 06 | 90000 | new random | 150 | 50 | (0.35, 0.55, 0.1), (0.5, 0.5, 0.1), (0.55, 0.35, 0.1) (3)| no | 2 |
| 07 | 129600 | new random | 60 | 15 | steps: 0.1 (36) | yes | no |
| 08 | 30240 | standard variations | 3 | 70 | steps: 0.1 (36) | yes | no |
| 09 | 314784 | standard example | 1 | 2186 | steps: 0.1 (36) | yes | no |

<!--
*Model explorations of ensembles 01 to 06*

There is a [template](https://git.scc.kit.edu/debatelab/re-python/-/blob/master/projects/ensemble_study_02/ensemble-study-02-dataexploration-template.ipynb) for the exploration of ensembles. It extracts the following information from an ensemble

- general points
- commitment consistency cases
- global optima and fixed points in relation to inferential density and size of sentence pool
- process length
- tau truths
- dynamics  of concrete examples

*Model validation with ensemble  07 to 09*

An important difference to earlier ensembles is the strict separation of global optima and fixed points with respect to relevant features such as RE states or commitment consistency cases. For every fixed point and every global optimum additional information is stored in the corresponding row (see [here](https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/documents/model-validation.md)).
-->

**Remarks for the interpretation or explanation** 

Due to the wide range of required inputs for a configuration, salient behaviour may depend on the features of any of i)-iv) or a combination thereof, and it is difficult to separate all dimension at once. In order to disentangle i) model variants  and iii) the weightings, heatmaps proved to be a useful tool and provided insightful plots with respect to various evaluation criteria. The other inputs involve much more features, which could explain salient behaviour, but are much harder to separate: 
- ii) features of dialectical structures include the size of the sentence pool, number of arguments, number of premises per argument, inferential density, number of complete consistent extensions, number of tau-truths.
- iv) features of initial commitments include their size, dialectical consistency, dialectical closure, number of complete consistent extensions, the minimal axiomatization

## Summary of results

In general, we did not find conclusive evidence to exclude a model variant as a future reference point. Each model variant satisfies the consolidation criteria to a sufficient degree for a wide range of configurations. At this point, undesirable behaviour (failing with respect to some criterion) cannot be attributed to a model variant on its own, but may result from a combination of other aspects of a configuration, such as unfavourable dialectical structures, extreme weightings or hopelessly absurd initial commitments. This does not mean, that there are no differences at all or no tendencies in favour of some model variants. Linear models tend to perform better as quadratic variants with respect to many criteria. 

<!-- 
Remarks: Currently I [BC] outcommented this para. 
+ ToDo: We should discuss, whether we want include analytical results in the standalone technical report.
+ Relevant documents:
    + <https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/documents/linear_models_tipping_line.md>
    + <https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/documents/Quadratic_Tipping-Line.md>
-->
<!--
In addition to the exploration of ensembles, there is a growing number of analytical results for both linear and quadratic models. Linear models have a ([tipping line](https://git.scc.kit.edu/debatelab/re-python/-/blob/master/projects/ensemble_study_02/documents/linear_models_tipping_line.md)), below which the weight for faithfulness makes no difference in the equilibration process towards fixed points ([see here](https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/documents/linear_models_tipping_line.md)). In quadratic models, the squaring of Hamming distances makes "midpoints" to attractors ([quadratic tipping](https://github.com/debatelab/re-studies/blob/master/projects/ensemble_study_02/documents/Quadratic_Tipping-Line.md)). Dependending on the interpretation of the consequences of such results, a model or specific configurations for a model may be preferred.
-->
If conceptual clarity is to be taken into account, pure systematicity (number of a theories sentences normalized by the size of the sentence pool)  may be preferred to default systematicity, which involves normalization by the size of a theory's closure (its "scope"). In the former case, pure systematicity may safely be called "simplicity" and other virtues contributing to the systematicityof a theory (e.g. scope) should be reserved for model extensions. In this line of thought, `LinearPureSystematicityRE` can be seen as the absolute minimal model variant, that is extended by the other variants by squaring measures, refining systematicity, or both.

